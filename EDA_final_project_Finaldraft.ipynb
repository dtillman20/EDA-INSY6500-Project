{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "719f5fc1-2940-4cbb-bc3b-149e7763ca0f",
   "metadata": {},
   "source": [
    "## EDA Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859d7cbd-9bf5-4520-aa2b-b9deabdd662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAWN Weather Data - Exploratory Data Analysis\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d12bef6-b953-4aca-a8db-16ff64634918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58473152-1377-4605-919c-0b1da9662be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "\n",
    "print(\"STEP 1: LOAD & INITIAL RECONNAISSANCE\")\n",
    "# Load the data\n",
    "df = pd.read_csv('c:/Users/USER/Downloads/FAWN_report.csv')\n",
    "\n",
    "print(\"\\n1.1 BASIC DATASET INFORMATION\")\n",
    "print(f\"Dataset Shape: {df.shape[0]} rows × {df.shape[1]} columns\")\n",
    "print(f\"Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "print(\"\\n1.2 COLUMN NAMES AND TYPES\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\n1.3 FIRST FEW ROWS\")\n",
    "print(df.head(10))\n",
    "\n",
    "print(\"\\n1.4 LAST FEW ROWS\")\n",
    "print(df.tail(10))\n",
    "\n",
    "print(\"\\n1.5 BASIC STATISTICS\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\n1.6 DATASET INFO\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\n1.7 UNIQUE VALUES IN CATEGORICAL COLUMNS\")\n",
    "print(f\"Number of unique FAWN Stations: {df['FAWN Station'].nunique()}\")\n",
    "print(f\"Unique Stations: {df['FAWN Station'].unique()}\")\n",
    "print(f\"\\nNumber of unique Periods: {df['Period'].nunique()}\")\n",
    "print(f\"Sample Periods: {df['Period'].unique()[:10]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29cdc17-1c85-43d6-b3e7-ef6f60e48506",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"STEP 2: DATA QUALITY ASSESSMENT\")\n",
    "\n",
    "print(\"\\n2.1 MISSING VALUES ANALYSIS\")\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (df.isnull().sum() / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing_Count': missing,\n",
    "    'Missing_Percentage': missing_pct\n",
    "}).sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "if missing_df['Missing_Count'].sum() > 0:\n",
    "    print(missing_df[missing_df['Missing_Count'] > 0])\n",
    "else:\n",
    "    print(\"No missing values detected in the dataset!\")\n",
    "    print(\"\\nAll columns have complete data:\")\n",
    "    print(missing_df.head())\n",
    "\n",
    "# Visualize missing data\n",
    "if missing_df['Missing_Count'].sum() > 0:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    missing_df[missing_df['Missing_Count'] > 0].plot(kind='bar', y='Missing_Percentage')\n",
    "    plt.title('Missing Data Percentage by Column')\n",
    "    plt.ylabel('Percentage Missing (%)')\n",
    "    plt.xlabel('Columns')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\" No missing values found in the dataset!\")\n",
    "\n",
    "print(\"\\n2.2 DATA TYPES CHECK\")\n",
    "print(\"Expected types vs Actual types:\")\n",
    "for col in df.columns:\n",
    "    print(f\"{col}: {df[col].dtype}\")\n",
    "\n",
    "# Check if Period should be datetime\n",
    "print(f\"\\nSample Period values: {df['Period'].head()}\")\n",
    "\n",
    "print(\"\\n2.3 DUPLICATE ROWS\")\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates}\")\n",
    "if duplicates > 0:\n",
    "    print(f\"Percentage of duplicates: {(duplicates/len(df))*100:.2f}%\")\n",
    "\n",
    "print(\"\\n2.4 OUTLIER DETECTION (IQR Method)\")\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "for col in numeric_cols:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)][col]\n",
    "    \n",
    "    if len(outliers) > 0:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  Outliers: {len(outliers)} ({(len(outliers)/len(df))*100:.2f}%)\")\n",
    "        print(f\"  Range: [{df[col].min():.2f}, {df[col].max():.2f}]\")\n",
    "        print(f\"  Expected range (IQR): [{lower_bound:.2f}, {upper_bound:.2f}]\")\n",
    "\n",
    "print(\"\\n2.5 ZERO/NEGATIVE VALUES CHECK\")\n",
    "for col in numeric_cols:\n",
    "    zeros = (df[col] == 0).sum()\n",
    "    negatives = (df[col] < 0).sum()\n",
    "    if zeros > 0 or negatives > 0:\n",
    "        print(f\"{col}: {zeros} zeros, {negatives} negative values\")\n",
    "\n",
    "print(\"\\n2.6 CONSISTENCY CHECKS\")\n",
    "# Check if min < avg < max for temperature\n",
    "temp_issues = df[\n",
    "    (df['2m T min (F)'] > df['2m T avg (F)']) | \n",
    "    (df['2m T avg (F)'] > df['2m T max (F)'])\n",
    "]\n",
    "print(f\"Temperature consistency issues: {len(temp_issues)} rows\")\n",
    "\n",
    "# Check if soil temp min < avg < max\n",
    "soil_issues = df[\n",
    "    (df['Tsoil min(avg)-10cm  (F)'] > df['Tsoil avg-10cm  (F)']) | \n",
    "    (df['Tsoil avg-10cm  (F)'] > df['Tsoil max(avg)-10cm  (F)'])\n",
    "]\n",
    "print(f\"Soil temperature consistency issues: {len(soil_issues)} rows\")\n",
    "\n",
    "# Check if wind min < avg < max\n",
    "wind_issues = df[\n",
    "    (df['10m Wind min (mph)'] > df['10m Wind avg (mph)']) | \n",
    "    (df['10m Wind avg (mph)'] > df['10m Wind max (mph)'])\n",
    "]\n",
    "print(f\"Wind speed consistency issues: {len(wind_issues)} rows\")\n",
    "\n",
    "print(\"\\n2.7 UNIQUE STATION ANALYSIS\")\n",
    "station_counts = df['FAWN Station'].value_counts()\n",
    "print(f\"Total stations: {len(station_counts)}\")\n",
    "print(f\"\\nObservations per station:\")\n",
    "print(station_counts.head(10))\n",
    "\n",
    "print(\"\\n2.8 DATA QUALITY SUMMARY\")\n",
    "print(\"Issues Found:\")\n",
    "print(f\" Missing values: {missing_df['Missing_Count'].sum()} total\")\n",
    "print(f\" Duplicates: {duplicates}\")\n",
    "print(f\" Potential outliers detected in multiple variables\")\n",
    "print(f\" Consistency issues in min/avg/max relationships\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e2c97c-85f8-4fca-b4ab-5b05dac42594",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"STEP 3: CLEANING DECISIONS AND IMPLEMENTATION\")\n",
    "\n",
    "print(f\"\\nOriginal dataset shape: {df.shape}\")\n",
    "\n",
    "# Create a copy for cleaning\n",
    "df_clean = df.copy()\n",
    "\n",
    "print(\"\\n3.1 HANDLE DUPLICATES\")\n",
    "duplicates_before = df_clean.duplicated().sum()\n",
    "df_clean = df_clean.drop_duplicates()\n",
    "print(f\"Duplicates removed: {duplicates_before}\")\n",
    "print(f\"New shape: {df_clean.shape}\")\n",
    "\n",
    "print(\"\\n3.2 FIX DATA TYPES\")\n",
    "# Convert Period to datetime\n",
    "try:\n",
    "    df_clean['Period'] = pd.to_datetime(df_clean['Period'])\n",
    "    print(\" Period converted to datetime\")\n",
    "except:\n",
    "    print(\" Could not convert Period to datetime - keeping as string\")\n",
    "\n",
    "# Ensure numeric columns are numeric\n",
    "numeric_columns = [\n",
    "    '2m T avg (F)', '2m T min (F)', '2m T max (F)',\n",
    "    'Tsoil avg-10cm  (F)', 'Tsoil min(avg)-10cm  (F)', 'Tsoil max(avg)-10cm  (F)',\n",
    "    '2m DewPt avg (F)', 'RelHum avg 2m  (pct)', '2m Rain tot (in)',\n",
    "    '2m Rain max over 15min (in)', 'SolRad avg2m  (w/m^2)',\n",
    "    '10m Wind avg (mph)', '10m Wind min (mph)', '10m Wind max (mph)',\n",
    "    'WDir avg10m  (deg)', 'BP avg (mb)', 'N (# obs)', '2m WetBulb (F)'\n",
    "]\n",
    "\n",
    "for col in numeric_columns:\n",
    "    df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')\n",
    "print(f\" Numeric columns verified\")\n",
    "\n",
    "print(\"\\n3.3 HANDLE MISSING VALUES\")\n",
    "missing_before = df_clean.isnull().sum().sum()\n",
    "\n",
    "# Decision rules for missing values:\n",
    "# 1. If a row has > 50% missing values, remove it\n",
    "threshold = 0.5 * len(df_clean.columns)\n",
    "df_clean = df_clean.dropna(thresh=threshold)\n",
    "print(f\"Rows with >50% missing removed: {len(df) - len(df_clean)}\")\n",
    "\n",
    "# 2. For specific columns with few missing values, use forward fill or interpolation\n",
    "for col in numeric_columns:\n",
    "    missing_pct = df_clean[col].isnull().sum() / len(df_clean)\n",
    "    if 0 < missing_pct < 0.05:  # Less than 5% missing\n",
    "        df_clean[col] = df_clean[col].interpolate(method='linear')\n",
    "        print(f\" {col}: Interpolated {missing_pct*100:.2f}% missing values\")\n",
    "\n",
    "missing_after = df_clean.isnull().sum().sum()\n",
    "print(f\"\\nMissing values: {missing_before} → {missing_after}\")\n",
    "\n",
    "print(\"\\n3.4 HANDLE OUTLIERS\")\n",
    "print(\"Decision: Keep outliers but flag them for investigation\")\n",
    "print(\"Rationale: Weather data can have legitimate extreme values\")\n",
    "\n",
    "# Flag extreme outliers (beyond 3 standard deviations)\n",
    "df_clean['has_outlier'] = False\n",
    "for col in numeric_columns:\n",
    "    if col in df_clean.columns:\n",
    "        mean = df_clean[col].mean()\n",
    "        std = df_clean[col].std()\n",
    "        outliers = (df_clean[col] < mean - 3*std) | (df_clean[col] > mean + 3*std)\n",
    "        df_clean.loc[outliers, 'has_outlier'] = True\n",
    "\n",
    "outlier_count = df_clean['has_outlier'].sum()\n",
    "print(f\"Rows flagged with extreme outliers: {outlier_count} ({outlier_count/len(df_clean)*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n3.5 FIX CONSISTENCY ISSUES\")\n",
    "# Fix temperature min/max issues\n",
    "temp_fixes = 0\n",
    "mask = df_clean['2m T min (F)'] > df_clean['2m T max (F)']\n",
    "if mask.sum() > 0:\n",
    "    # Swap min and max if inverted\n",
    "    df_clean.loc[mask, ['2m T min (F)', '2m T max (F)']] = df_clean.loc[mask, ['2m T max (F)', '2m T min (F)']].values\n",
    "    temp_fixes = mask.sum()\n",
    "print(f\"Temperature min/max swapped: {temp_fixes} rows\")\n",
    "\n",
    "# Fix soil temperature issues\n",
    "soil_fixes = 0\n",
    "mask = df_clean['Tsoil min(avg)-10cm  (F)'] > df_clean['Tsoil max(avg)-10cm  (F)']\n",
    "if mask.sum() > 0:\n",
    "    df_clean.loc[mask, ['Tsoil min(avg)-10cm  (F)', 'Tsoil max(avg)-10cm  (F)']] = \\\n",
    "        df_clean.loc[mask, ['Tsoil max(avg)-10cm  (F)', 'Tsoil min(avg)-10cm  (F)']].values\n",
    "    soil_fixes = mask.sum()\n",
    "print(f\"Soil temperature min/max swapped: {soil_fixes} rows\")\n",
    "\n",
    "# Fix wind speed issues\n",
    "wind_fixes = 0\n",
    "mask = df_clean['10m Wind min (mph)'] > df_clean['10m Wind max (mph)']\n",
    "if mask.sum() > 0:\n",
    "    df_clean.loc[mask, ['10m Wind min (mph)', '10m Wind max (mph)']] = \\\n",
    "        df_clean.loc[mask, ['10m Wind max (mph)', '10m Wind min (mph)']].values\n",
    "    wind_fixes = mask.sum()\n",
    "print(f\"Wind speed min/max swapped: {wind_fixes} rows\")\n",
    "\n",
    "print(\"\\n3.6 REMOVE INVALID RECORDS\")\n",
    "# Remove records with impossible values\n",
    "initial_len = len(df_clean)\n",
    "\n",
    "# Temperature should be within reasonable Florida range\n",
    "df_clean = df_clean[\n",
    "    (df_clean['2m T avg (F)'] >= -20) & \n",
    "    (df_clean['2m T avg (F)'] <= 120)\n",
    "]\n",
    "\n",
    "# Humidity should be 0-100%\n",
    "df_clean = df_clean[\n",
    "    (df_clean['RelHum avg 2m  (pct)'] >= 0) & \n",
    "    (df_clean['RelHum avg 2m  (pct)'] <= 100)\n",
    "]\n",
    "\n",
    "# Rain cannot be negative\n",
    "df_clean = df_clean[df_clean['2m Rain tot (in)'] >= 0]\n",
    "\n",
    "# Wind direction should be 0-360 degrees\n",
    "df_clean = df_clean[\n",
    "    (df_clean['WDir avg10m  (deg)'] >= 0) & \n",
    "    (df_clean['WDir avg10m  (deg)'] <= 360)\n",
    "]\n",
    "\n",
    "removed = initial_len - len(df_clean)\n",
    "print(f\"Invalid records removed: {removed}\")\n",
    "\n",
    "print(\"\\n3.7 SAVE CLEANED DATA\")\n",
    "df_clean.to_csv('FAWN_report_cleaned.csv', index=False)\n",
    "print(\" Cleaned data saved to: FAWN_report_cleaned.csv\")\n",
    "\n",
    "print(\"\\n3.8 CLEANING SUMMARY\")\n",
    "print(f\"Original shape: {df.shape}\")\n",
    "print(f\"Cleaned shape: {df_clean.shape}\")\n",
    "print(f\"Rows removed: {len(df) - len(df_clean)} ({((len(df) - len(df_clean))/len(df))*100:.2f}%)\")\n",
    "print(f\"Columns added: 1 (has_outlier flag)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4bb0db-b3d2-464d-a9e8-72be4657754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"STEP 4: STATISTICAL EXPLORATORY DATA ANALYSIS\")\n",
    "\n",
    "# UNIVARIATE ANALYSIS\n",
    "print(\"\\n4.1 UNIVARIATE ANALYSIS - DISTRIBUTIONS\")\n",
    "\n",
    "# Temperature distribution\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "fig.suptitle('Weather Variables Distributions', fontsize=16)\n",
    "\n",
    "# Temperature\n",
    "axes[0, 0].hist(df['2m T avg (F)'].dropna(), bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].set_title('Air Temperature Distribution')\n",
    "axes[0, 0].set_xlabel('Temperature (F)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Humidity\n",
    "axes[0, 1].hist(df['RelHum avg 2m  (pct)'].dropna(), bins=50, edgecolor='black', alpha=0.7, color='green')\n",
    "axes[0, 1].set_title('Relative Humidity Distribution')\n",
    "axes[0, 1].set_xlabel('Humidity (%)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Rainfall\n",
    "axes[0, 2].hist(df['2m Rain tot (in)'].dropna(), bins=50, edgecolor='black', alpha=0.7, color='blue')\n",
    "axes[0, 2].set_title('Total Rainfall Distribution')\n",
    "axes[0, 2].set_xlabel('Rainfall (inches)')\n",
    "axes[0, 2].set_ylabel('Frequency')\n",
    "\n",
    "# Wind Speed\n",
    "axes[1, 0].hist(df['10m Wind avg (mph)'].dropna(), bins=50, edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[1, 0].set_title('Wind Speed Distribution')\n",
    "axes[1, 0].set_xlabel('Wind Speed (mph)')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Solar Radiation\n",
    "axes[1, 1].hist(df['SolRad avg2m  (w/m^2)'].dropna(), bins=50, edgecolor='black', alpha=0.7, color='yellow')\n",
    "axes[1, 1].set_title('Solar Radiation Distribution')\n",
    "axes[1, 1].set_xlabel('Solar Radiation (w/m²)')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Barometric Pressure\n",
    "axes[1, 2].hist(df['BP avg (mb)'].dropna(), bins=50, edgecolor='black', alpha=0.7, color='purple')\n",
    "axes[1, 2].set_title('Barometric Pressure Distribution')\n",
    "axes[1, 2].set_xlabel('Pressure (mb)')\n",
    "axes[1, 2].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# BIVARIATE ANALYSIS\n",
    "print(\"\\n4.2 BIVARIATE ANALYSIS - RELATIONSHIPS\")\n",
    "\n",
    "# Correlation matrix\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "correlation_matrix = df[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1)\n",
    "plt.title('Correlation Matrix - Weather Variables', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Strong correlations\n",
    "print(\"\\nStrongest Correlations (|r| > 0.5):\")\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.5:\n",
    "            print(f\"{correlation_matrix.columns[i]} ↔ {correlation_matrix.columns[j]}: {correlation_matrix.iloc[i, j]:.3f}\")\n",
    "\n",
    "# Key scatter plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('Key Relationships in Weather Data', fontsize=16)\n",
    "\n",
    "# Temperature vs Humidity\n",
    "axes[0, 0].scatter(df['2m T avg (F)'], df['RelHum avg 2m  (pct)'], alpha=0.3)\n",
    "axes[0, 0].set_xlabel('Temperature (F)')\n",
    "axes[0, 0].set_ylabel('Humidity (%)')\n",
    "axes[0, 0].set_title('Temperature vs Humidity')\n",
    "\n",
    "# Temperature vs Dew Point\n",
    "axes[0, 1].scatter(df['2m T avg (F)'], df['2m DewPt avg (F)'], alpha=0.3, color='green')\n",
    "axes[0, 1].set_xlabel('Temperature (F)')\n",
    "axes[0, 1].set_ylabel('Dew Point (F)')\n",
    "axes[0, 1].set_title('Temperature vs Dew Point')\n",
    "\n",
    "# Solar Radiation vs Temperature\n",
    "axes[1, 0].scatter(df['SolRad avg2m  (w/m^2)'], df['2m T avg (F)'], alpha=0.3, color='orange')\n",
    "axes[1, 0].set_xlabel('Solar Radiation (w/m²)')\n",
    "axes[1, 0].set_ylabel('Temperature (F)')\n",
    "axes[1, 0].set_title('Solar Radiation vs Temperature')\n",
    "\n",
    "# Wind Speed vs Temperature\n",
    "axes[1, 1].scatter(df['10m Wind avg (mph)'], df['2m T avg (F)'], alpha=0.3, color='red')\n",
    "axes[1, 1].set_xlabel('Wind Speed (mph)')\n",
    "axes[1, 1].set_ylabel('Temperature (F)')\n",
    "axes[1, 1].set_title('Wind Speed vs Temperature')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# CATEGORICAL ANALYSIS\n",
    "print(\"\\n4.3 CATEGORICAL ANALYSIS - BY STATION\")\n",
    "\n",
    "# Temperature by station\n",
    "station_stats = df.groupby('FAWN Station').agg({\n",
    "    '2m T avg (F)': ['mean', 'std', 'min', 'max'],\n",
    "    '2m Rain tot (in)': 'sum',\n",
    "    '10m Wind avg (mph)': 'mean',\n",
    "    'RelHum avg 2m  (pct)': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "print(\"\\nStation-level Summary:\")\n",
    "print(station_stats.head(10))\n",
    "\n",
    "# Box plot of temperature by station (top 10 stations)\n",
    "top_stations = df['FAWN Station'].value_counts().head(10).index\n",
    "df_top = df[df['FAWN Station'].isin(top_stations)]\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "df_top.boxplot(column='2m T avg (F)', by='FAWN Station', figsize=(14, 6))\n",
    "plt.title('Temperature Distribution by Station (Top 10)')\n",
    "plt.suptitle('')\n",
    "plt.xlabel('Station')\n",
    "plt.ylabel('Temperature (F)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# TIME SERIES PATTERNS\n",
    "print(\"\\n4.4 TEMPORAL PATTERNS\")\n",
    "\n",
    "if 'Period' in df.columns:\n",
    "    try:\n",
    "        df['Period'] = pd.to_datetime(df['Period'])\n",
    "        df_time = df.sort_values('Period')\n",
    "        \n",
    "        # Plot temperature over time\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        plt.plot(df_time['Period'], df_time['2m T avg (F)'], alpha=0.5)\n",
    "        plt.title('Temperature Over Time')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Temperature (F)')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\" Temporal patterns visualized\")\n",
    "    except:\n",
    "        print(\" Could not analyze temporal patterns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2629ace-1e05-4b19-b43c-0f8a1ca945a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"STEP 5: TRANSFORMATION & FEATURE ENGINEERING\")\n",
    "\n",
    "print(f\"\\nOriginal shape: {df.shape}\")\n",
    "\n",
    "# DATETIME FEATURES\n",
    "print(\"\\n5.1 EXTRACT TEMPORAL FEATURES\")\n",
    "\n",
    "if 'Period' in df.columns:\n",
    "    df['Period'] = pd.to_datetime(df['Period'], errors='coerce')\n",
    "    df['Year'] = df['Period'].dt.year\n",
    "    df['Month'] = df['Period'].dt.month\n",
    "    df['Day'] = df['Period'].dt.day\n",
    "    df['DayOfWeek'] = df['Period'].dt.dayofweek\n",
    "    df['Quarter'] = df['Period'].dt.quarter\n",
    "    df['WeekOfYear'] = df['Period'].dt.isocalendar().week\n",
    "    df['Season'] = df['Month'].map({\n",
    "        12: 'Winter', 1: 'Winter', 2: 'Winter',\n",
    "        3: 'Spring', 4: 'Spring', 5: 'Spring',\n",
    "        6: 'Summer', 7: 'Summer', 8: 'Summer',\n",
    "        9: 'Fall', 10: 'Fall', 11: 'Fall'\n",
    "    })\n",
    "    print(\" Created: Year, Month, Day, DayOfWeek, Quarter, WeekOfYear, Season\")\n",
    "\n",
    "# TEMPERATURE FEATURES\n",
    "print(\"\\n5.2 ENGINEER TEMPERATURE FEATURES\")\n",
    "\n",
    "# Temperature range (daily variation)\n",
    "df['Temp_Range'] = df['2m T max (F)'] - df['2m T min (F)']\n",
    "\n",
    "# Soil temperature range\n",
    "df['Soil_Temp_Range'] = df['Tsoil max(avg)-10cm  (F)'] - df['Tsoil min(avg)-10cm  (F)']\n",
    "\n",
    "# Temperature categories\n",
    "df['Temp_Category'] = pd.cut(df['2m T avg (F)'], \n",
    "                              bins=[-np.inf, 32, 50, 70, 85, np.inf],\n",
    "                              labels=['Freezing', 'Cold', 'Mild', 'Warm', 'Hot'])\n",
    "\n",
    "# Heat index approximation (simplified)\n",
    "df['Apparent_Temp'] = df['2m T avg (F)'] + 0.33 * df['RelHum avg 2m  (pct)'] / 100 * (df['2m T avg (F)'] - 70)\n",
    "\n",
    "print(\" Created: Temp_Range, Soil_Temp_Range, Temp_Category, Apparent_Temp\")\n",
    "\n",
    "# WIND FEATURES\n",
    "print(\"\\n5.3 ENGINEER WIND FEATURES\")\n",
    "\n",
    "# Wind speed range\n",
    "df['Wind_Range'] = df['10m Wind max (mph)'] - df['10m Wind min (mph)']\n",
    "\n",
    "# Wind categories\n",
    "df['Wind_Category'] = pd.cut(df['10m Wind avg (mph)'],\n",
    "                              bins=[0, 5, 10, 15, 25, np.inf],\n",
    "                              labels=['Calm', 'Light', 'Moderate', 'Fresh', 'Strong'])\n",
    "\n",
    "# Wind chill (when temp < 50F and wind > 3 mph)\n",
    "mask = (df['2m T avg (F)'] < 50) & (df['10m Wind avg (mph)'] > 3)\n",
    "df['Wind_Chill'] = np.where(\n",
    "    mask,\n",
    "    35.74 + 0.6215 * df['2m T avg (F)'] - 35.75 * (df['10m Wind avg (mph)'] ** 0.16) + \n",
    "    0.4275 * df['2m T avg (F)'] * (df['10m Wind avg (mph)'] ** 0.16),\n",
    "    df['2m T avg (F)']\n",
    ")\n",
    "\n",
    "print(\" Created: Wind_Range, Wind_Category, Wind_Chill\")\n",
    "\n",
    "# PRECIPITATION FEATURES\n",
    "print(\"\\n5.4 ENGINEER PRECIPITATION FEATURES\")\n",
    "\n",
    "# Rain intensity categories\n",
    "df['Rain_Category'] = pd.cut(df['2m Rain tot (in)'],\n",
    "                              bins=[-0.001, 0, 0.1, 0.5, 1.0, np.inf],\n",
    "                              labels=['No Rain', 'Light', 'Moderate', 'Heavy', 'Very Heavy'])\n",
    "\n",
    "# Rain flag\n",
    "df['Has_Rain'] = (df['2m Rain tot (in)'] > 0).astype(int)\n",
    "\n",
    "# Rain intensity (rain per 15min period)\n",
    "df['Rain_Intensity'] = df['2m Rain max over 15min (in)'] / 0.25  # per hour\n",
    "\n",
    "print(\" Created: Rain_Category, Has_Rain, Rain_Intensity\")\n",
    "\n",
    "# HUMIDITY & DEW POINT FEATURES\n",
    "print(\"\\n5.5 ENGINEER HUMIDITY FEATURES\")\n",
    "\n",
    "# Humidity comfort categories\n",
    "df['Humidity_Comfort'] = pd.cut(df['RelHum avg 2m  (pct)'],\n",
    "                                 bins=[0, 30, 60, 80, 100],\n",
    "                                 labels=['Dry', 'Comfortable', 'Humid', 'Very Humid'])\n",
    "\n",
    "# Dew point comfort (based on dew point temperature)\n",
    "df['Dewpoint_Comfort'] = pd.cut(df['2m DewPt avg (F)'],\n",
    "                                bins=[-np.inf, 50, 60, 65, 70, np.inf],\n",
    "                                labels=['Dry', 'Comfortable', 'Sticky', 'Uncomfortable', 'Oppressive'])\n",
    "\n",
    "print(\" Created: Humidity_Comfort, Dewpoint_Comfort\")\n",
    "\n",
    "# SOLAR RADIATION FEATURES\n",
    "print(\"\\n5.6 ENGINEER SOLAR FEATURES\")\n",
    "\n",
    "# Solar radiation categories\n",
    "df['Solar_Category'] = pd.cut(df['SolRad avg2m  (w/m^2)'],\n",
    "                               bins=[0, 200, 400, 600, 800, np.inf],\n",
    "                               labels=['Low', 'Moderate', 'High', 'Very High', 'Extreme'])\n",
    "\n",
    "print(\" Created: Solar_Category\")\n",
    "\n",
    "# COMPOSITE FEATURES\n",
    "print(\"\\n5.7 CREATE COMPOSITE INDICES\")\n",
    "\n",
    "# Comfort index (normalized combination of temp, humidity, wind)\n",
    "scaler = StandardScaler()\n",
    "comfort_features = df[['2m T avg (F)', 'RelHum avg 2m  (pct)', '10m Wind avg (mph)']].copy()\n",
    "comfort_scaled = scaler.fit_transform(comfort_features.fillna(comfort_features.mean()))\n",
    "df['Comfort_Index'] = 100 - np.mean(np.abs(comfort_scaled), axis=1) * 20\n",
    "\n",
    "# Weather severity index (combination of extremes)\n",
    "df['Weather_Severity'] = (\n",
    "    np.abs(df['2m T avg (F)'] - 70) / 20 +  # Temperature deviation\n",
    "    df['10m Wind avg (mph)'] / 25 +  # Wind factor\n",
    "    df['2m Rain tot (in)'] * 2  # Rain factor\n",
    ")\n",
    "\n",
    "print(\" Created: Comfort_Index, Weather_Severity\")\n",
    "\n",
    "# STATION AGGREGATIONS\n",
    "print(\"\\n5.8 CREATE STATION-LEVEL FEATURES\")\n",
    "\n",
    "# Average conditions by station\n",
    "station_avg_temp = df.groupby('FAWN Station')['2m T avg (F)'].transform('mean')\n",
    "df['Station_Avg_Temp'] = station_avg_temp\n",
    "\n",
    "station_avg_rain = df.groupby('FAWN Station')['2m Rain tot (in)'].transform('mean')\n",
    "df['Station_Avg_Rain'] = station_avg_rain\n",
    "\n",
    "# Deviation from station average\n",
    "df['Temp_Deviation_From_Station'] = df['2m T avg (F)'] - df['Station_Avg_Temp']\n",
    "\n",
    "print(\" Created: Station_Avg_Temp, Station_Avg_Rain, Temp_Deviation_From_Station\")\n",
    "\n",
    "# INTERACTION FEATURES\n",
    "print(\"\\n5.9 CREATE INTERACTION FEATURES\")\n",
    "\n",
    "# Temperature * Humidity interaction\n",
    "df['Temp_Humidity_Interaction'] = df['2m T avg (F)'] * df['RelHum avg 2m  (pct)']\n",
    "\n",
    "# Wind * Rain interaction (storm indicator)\n",
    "df['Wind_Rain_Interaction'] = df['10m Wind avg (mph)'] * df['2m Rain tot (in)']\n",
    "\n",
    "print(\" Created: Temp_Humidity_Interaction, Wind_Rain_Interaction\")\n",
    "\n",
    "# SAVE TRANSFORMED DATA\n",
    "print(\"\\n5.10 SAVE FEATURE-ENGINEERED DATASET\")\n",
    "df.to_csv('FAWN_report_features.csv', index=False)\n",
    "print(f\" Saved: FAWN_report_features.csv\")\n",
    "print(f\"Final shape: {df.shape}\")\n",
    "print(f\"New features created: {df.shape[1] - 20}\")\n",
    "\n",
    "# VISUALIZE NEW FEATURES\n",
    "print(\"\\n5.11 VISUALIZE ENGINEERED FEATURES\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "fig.suptitle('Engineered Features Visualizations', fontsize=16)\n",
    "\n",
    "# Temperature by Season\n",
    "df.boxplot(column='2m T avg (F)', by='Season', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Temperature by Season')\n",
    "axes[0, 0].set_xlabel('Season')\n",
    "axes[0, 0].set_ylabel('Temperature (F)')\n",
    "\n",
    "# Rain by Category\n",
    "df['Rain_Category'].value_counts().plot(kind='bar', ax=axes[0, 1], color='blue')\n",
    "axes[0, 1].set_title('Rain Category Distribution')\n",
    "axes[0, 1].set_xlabel('Category')\n",
    "axes[0, 1].set_ylabel('Count')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Comfort Index distribution\n",
    "axes[0, 2].hist(df['Comfort_Index'].dropna(), bins=50, edgecolor='black', alpha=0.7, color='green')\n",
    "axes[0, 2].set_title('Comfort Index Distribution')\n",
    "axes[0, 2].set_xlabel('Comfort Index')\n",
    "axes[0, 2].set_ylabel('Frequency')\n",
    "\n",
    "# Weather Severity\n",
    "axes[1, 0].hist(df['Weather_Severity'].dropna(), bins=50, edgecolor='black', alpha=0.7, color='red')\n",
    "axes[1, 0].set_title('Weather Severity Index')\n",
    "axes[1, 0].set_xlabel('Severity')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Temperature Range\n",
    "axes[1, 1].hist(df['Temp_Range'].dropna(), bins=50, edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[1, 1].set_title('Daily Temperature Range')\n",
    "axes[1, 1].set_xlabel('Range (F)')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Wind Category\n",
    "df['Wind_Category'].value_counts().plot(kind='bar', ax=axes[1, 2], color='purple')\n",
    "axes[1, 2].set_title('Wind Category Distribution')\n",
    "axes[1, 2].set_xlabel('Category')\n",
    "axes[1, 2].set_ylabel('Count')\n",
    "axes[1, 2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adb577e-f287-47d1-ab9d-c95da063f3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"STEP 6: SAVE & DOCUMENT\")\n",
    "\n",
    "# CREATE DATA DICTIONARY\n",
    "print(\"\\n6.1 GENERATE DATA DICTIONARY\")\n",
    "\n",
    "data_dict = {\n",
    "    'Column_Name': [],\n",
    "    'Data_Type': [],\n",
    "    'Description': [],\n",
    "    'Non_Null_Count': [],\n",
    "    'Unique_Values': [],\n",
    "    'Sample_Values': []\n",
    "}\n",
    "\n",
    "for col in df.columns:\n",
    "    data_dict['Column_Name'].append(col)\n",
    "    data_dict['Data_Type'].append(str(df[col].dtype))\n",
    "    data_dict['Non_Null_Count'].append(df[col].notna().sum())\n",
    "    data_dict['Unique_Values'].append(df[col].nunique())\n",
    "    \n",
    "    # Sample values\n",
    "    if df[col].dtype in ['object', 'category']:\n",
    "        sample = df[col].dropna().unique()[:3].tolist()\n",
    "    else:\n",
    "        sample = [f\"{df[col].min():.2f}\", f\"{df[col].mean():.2f}\", f\"{df[col].max():.2f}\"]\n",
    "    data_dict['Sample_Values'].append(str(sample))\n",
    "    \n",
    "    # Descriptions\n",
    "    descriptions = {\n",
    "        'FAWN Station': 'Weather station identifier',\n",
    "        'Period': 'Date/time of observation',\n",
    "        '2m T avg (F)': 'Average air temperature at 2m height',\n",
    "        '2m T min (F)': 'Minimum air temperature at 2m height',\n",
    "        '2m T max (F)': 'Maximum air temperature at 2m height',\n",
    "        'Temp_Range': 'Daily temperature range (max - min)',\n",
    "        'Temp_Category': 'Categorized temperature (Freezing/Cold/Mild/Warm/Hot)',\n",
    "        'Season': 'Season of the year',\n",
    "        'Rain_Category': 'Rainfall intensity category',\n",
    "        'Comfort_Index': 'Weather comfort score (0-100)',\n",
    "        'Weather_Severity': 'Weather severity index',\n",
    "    }\n",
    "    data_dict['Description'].append(descriptions.get(col, 'See documentation'))\n",
    "\n",
    "dict_df = pd.DataFrame(data_dict)\n",
    "dict_df.to_csv('FAWN_data_dictionary.csv', index=False)\n",
    "print(\"✓ Data dictionary saved: FAWN_data_dictionary.csv\")\n",
    "print(dict_df.head(10))\n",
    "\n",
    "# GENERATE ANALYSIS REPORT\n",
    "print(\"\\n6.2 CREATE ANALYSIS SUMMARY REPORT\")\n",
    "\n",
    "# Calculate statistics safely\n",
    "avg_temp = df['2m T avg (F)'].mean()\n",
    "temp_min = df['2m T min (F)'].min()\n",
    "temp_max = df['2m T max (F)'].max()\n",
    "total_rain = df['2m Rain tot (in)'].sum()\n",
    "rain_days = (df['2m Rain tot (in)'] > 0).sum()\n",
    "rain_pct = (rain_days / len(df) * 100) if len(df) > 0 else 0\n",
    "avg_rain_per_event = df[df['2m Rain tot (in)'] > 0]['2m Rain tot (in)'].mean() if rain_days > 0 else 0\n",
    "avg_wind = df['10m Wind avg (mph)'].mean()\n",
    "max_wind = df['10m Wind max (mph)'].max()\n",
    "avg_humidity = df['RelHum avg 2m  (pct)'].mean()\n",
    "num_stations = df['FAWN Station'].nunique()\n",
    "most_active = df['FAWN Station'].value_counts().index[0]\n",
    "records_per_station = len(df) / num_stations if num_stations > 0 else 0\n",
    "\n",
    "# Correlations\n",
    "temp_dewpt_corr = df[['2m T avg (F)', '2m DewPt avg (F)']].corr().iloc[0,1]\n",
    "temp_soil_corr = df[['2m T avg (F)', 'Tsoil avg-10cm  (F)']].corr().iloc[0,1]\n",
    "temp_humid_corr = df[['2m T avg (F)', 'RelHum avg 2m  (pct)']].corr().iloc[0,1]\n",
    "\n",
    "# Optional features\n",
    "temp_category = df['Temp_Category'].mode()[0] if 'Temp_Category' in df.columns and len(df['Temp_Category'].mode()) > 0 else 'N/A'\n",
    "wind_category = df['Wind_Category'].mode()[0] if 'Wind_Category' in df.columns and len(df['Wind_Category'].mode()) > 0 else 'N/A'\n",
    "avg_comfort = df['Comfort_Index'].mean() if 'Comfort_Index' in df.columns else 'N/A'\n",
    "\n",
    "report = f\"\"\"\n",
    "FAWN WEATHER DATA - EXPLORATORY DATA ANALYSIS REPORT\n",
    "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "DATASET OVERVIEW\n",
    "Original Records: 6,572\n",
    "Final Records: {len(df):,}\n",
    "Original Features: 20\n",
    "Engineered Features: {len(df.columns) - 20}\n",
    "Total Features: {len(df.columns)}\n",
    "\n",
    "DATA QUALITY SUMMARY\n",
    "Missing Values Handled: Yes\n",
    "Duplicates Removed: Yes\n",
    "Outliers Flagged: Yes\n",
    "Consistency Issues Fixed: Yes\n",
    "Invalid Records Removed: Yes\n",
    "\n",
    "KEY FINDINGS\n",
    "\n",
    "1. TEMPERATURE PATTERNS\n",
    "   - Average Temperature: {avg_temp:.2f}°F\n",
    "   - Temperature Range: {temp_min:.2f}°F to {temp_max:.2f}°F\n",
    "   - Most Common Category: {temp_category}\n",
    "\n",
    "2. PRECIPITATION PATTERNS\n",
    "   - Total Rainfall Recorded: {total_rain:.2f} inches\n",
    "   - Days with Rain: {rain_days} ({rain_pct:.1f}%)\n",
    "   - Average Rain per Event: {avg_rain_per_event:.3f} inches\n",
    "\n",
    "3. WIND PATTERNS\n",
    "   - Average Wind Speed: {avg_wind:.2f} mph\n",
    "   - Max Wind Speed: {max_wind:.2f} mph\n",
    "   - Predominant Wind Category: {wind_category}\n",
    "\n",
    "4. HUMIDITY & COMFORT\n",
    "   - Average Humidity: {avg_humidity:.1f}%\n",
    "   - Average Comfort Index: {avg_comfort if isinstance(avg_comfort, str) else f'{avg_comfort:.2f}'}\n",
    "   \n",
    "5. STATION ANALYSIS\n",
    "   - Number of Stations: {num_stations}\n",
    "   - Most Active Station: {most_active}\n",
    "   - Records per Station (avg): {records_per_station:.0f}\n",
    "\n",
    "CORRELATIONS DISCOVERED\n",
    "Strong positive correlations:\n",
    "- Temperature <-> Dew Point: {temp_dewpt_corr:.3f}\n",
    "- Air Temp <-> Soil Temp: {temp_soil_corr:.3f}\n",
    "\n",
    "Strong negative correlations:\n",
    "- Temperature <-> Humidity: {temp_humid_corr:.3f}\n",
    "\n",
    "FEATURE ENGINEERING SUMMARY\n",
    "Created Features:\n",
    "+ Temporal: Year, Month, Season, Quarter, DayOfWeek\n",
    "+ Temperature: Temp_Range, Temp_Category, Apparent_Temp, Wind_Chill\n",
    "+ Wind: Wind_Range, Wind_Category, Wind_Chill\n",
    "+ Precipitation: Rain_Category, Has_Rain, Rain_Intensity\n",
    "+ Composite: Comfort_Index, Weather_Severity\n",
    "+ Station-level: Station averages and deviations\n",
    "+ Interactions: Temp*Humidity, Wind*Rain\n",
    "\n",
    "DATA QUALITY ACTIONS TAKEN\n",
    "1. Removed {6572 - len(df)} rows with data quality issues\n",
    "2. Fixed min/max inversions in temperature, wind, and soil temp\n",
    "3. Interpolated missing values where appropriate\n",
    "4. Flagged extreme outliers for investigation\n",
    "5. Validated all measurements within reasonable ranges\n",
    "\"\"\"\n",
    "\n",
    "# Save report\n",
    "with open('FAWN_analysis_report.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(\"✓ Analysis report saved: FAWN_analysis_report.txt\")\n",
    "print(report)\n",
    "\n",
    "# === CREATE FINAL VISUALIZATIONS ===\n",
    "print(\"\\n6.3 GENERATE FINAL SUMMARY VISUALIZATIONS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Title\n",
    "fig.suptitle('FAWN Weather Data - Executive Summary Dashboard', fontsize=18, fontweight='bold')\n",
    "\n",
    "# 1. Temperature Over Time\n",
    "if 'Period' in df.columns:\n",
    "    ax1 = fig.add_subplot(gs[0, :])\n",
    "    df_sorted = df.sort_values('Period')\n",
    "    ax1.plot(pd.to_datetime(df_sorted['Period']), df_sorted['2m T avg (F)'], alpha=0.6)\n",
    "    ax1.set_title('Temperature Trend Over Time', fontsize=12, fontweight='bold')\n",
    "    ax1.set_xlabel('Date')\n",
    "    ax1.set_ylabel('Temperature (°F)')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Temperature Distribution by Season\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "if 'Season' in df.columns:\n",
    "    df.boxplot(column='2m T avg (F)', by='Season', ax=ax2)\n",
    "    ax2.set_title('Temperature by Season', fontsize=10, fontweight='bold')\n",
    "    ax2.set_xlabel('Season')\n",
    "    ax2.set_ylabel('Temperature (°F)')\n",
    "    plt.sca(ax2)\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "# 3. Rainfall Distribution\n",
    "ax3 = fig.add_subplot(gs[1, 1])\n",
    "rain_data = df[df['2m Rain tot (in)'] > 0]['2m Rain tot (in)']\n",
    "ax3.hist(rain_data, bins=30, edgecolor='black', alpha=0.7, color='blue')\n",
    "ax3.set_title('Rainfall Distribution (Rain Days Only)', fontsize=10, fontweight='bold')\n",
    "ax3.set_xlabel('Rainfall (inches)')\n",
    "ax3.set_ylabel('Frequency')\n",
    "\n",
    "# 4. Wind Speed Distribution\n",
    "ax4 = fig.add_subplot(gs[1, 2])\n",
    "ax4.hist(df['10m Wind avg (mph)'].dropna(), bins=30, edgecolor='black', alpha=0.7, color='orange')\n",
    "ax4.set_title('Wind Speed Distribution', fontsize=10, fontweight='bold')\n",
    "ax4.set_xlabel('Wind Speed (mph)')\n",
    "ax4.set_ylabel('Frequency')\n",
    "\n",
    "# 5. Temperature vs Humidity\n",
    "ax5 = fig.add_subplot(gs[2, 0])\n",
    "ax5.scatter(df['2m T avg (F)'], df['RelHum avg 2m  (pct)'], alpha=0.3, s=10)\n",
    "ax5.set_title('Temperature vs Humidity', fontsize=10, fontweight='bold')\n",
    "ax5.set_xlabel('Temperature (°F)')\n",
    "ax5.set_ylabel('Humidity (%)')\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Station Activity\n",
    "ax6 = fig.add_subplot(gs[2, 1])\n",
    "station_counts = df['FAWN Station'].value_counts().head(10)\n",
    "station_counts.plot(kind='barh', ax=ax6, color='green')\n",
    "ax6.set_title('Top 10 Stations by Records', fontsize=10, fontweight='bold')\n",
    "ax6.set_xlabel('Number of Records')\n",
    "ax6.set_ylabel('Station')\n",
    "\n",
    "# 7. Weather Severity\n",
    "ax7 = fig.add_subplot(gs[2, 2])\n",
    "if 'Weather_Severity' in df.columns:\n",
    "    ax7.hist(df['Weather_Severity'].dropna(), bins=30, edgecolor='black', alpha=0.7, color='red')\n",
    "    ax7.set_title('Weather Severity Index', fontsize=10, fontweight='bold')\n",
    "    ax7.set_xlabel('Severity Score')\n",
    "    ax7.set_ylabel('Frequency')\n",
    "\n",
    "plt.savefig('FAWN_summary_dashboard.png', dpi=300, bbox_inches='tight')\n",
    "print(\"✓ Summary dashboard saved: FAWN_summary_dashboard.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772a29f2-87df-4cf3-a44f-f4cbd5a0b5dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778ed021-8338-44c0-ae2d-770a700960d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa8a4f4-1970-44cd-8493-7a881355df35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656346bc-e268-4508-89ea-2e7957b78b75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e85806-d176-4d75-bf5d-216273142c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
